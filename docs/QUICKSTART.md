# Load Balancer - Quickstart Guide

Get your production-grade load balancer running in under 5 minutes!

## üöÄ Quick Setup

### Prerequisites
- Go 1.21+ (for building from source)
- OR Docker (for containerized deployment)
- Backend servers to load balance

### Option 1: Binary Installation (Fastest)

```bash
# 1. Clone the repository
git clone https://github.com/Mir00r/Load-Balancer.git
cd Load-Balancer

# 2. Build the load balancer
go build -o bin/load-balancer cmd/server/main.go

# 3. Start with default backends (modify as needed)
export LB_BACKENDS="http://localhost:3001,http://localhost:3002,http://localhost:3003"
./bin/load-balancer
```

üéâ **Load balancer is now running on http://localhost:8080**

### Option 2: Docker (Recommended for Production)

```bash
# 1. Build Docker image
docker build -t load-balancer:latest .

# 2. Run with your backends
docker run -d \
  --name load-balancer \
  -p 8080:8080 \
  -e LB_BACKENDS="http://app1:8080,http://app2:8080" \
  -e LB_STRATEGY="round_robin" \
  load-balancer:latest
```

## ‚ö° 30-Second Test

Start sample backend servers and test load balancing:

```bash
# Terminal 1: Start sample backends
python3 -m http.server 3001 &
python3 -m http.server 3002 &
python3 -m http.server 3003 &

# Terminal 2: Start load balancer
export LB_BACKENDS="http://localhost:3001,http://localhost:3002,http://localhost:3003"
./bin/load-balancer

# Terminal 3: Test load balancing
for i in {1..6}; do curl http://localhost:8080; echo; done
```

You'll see requests distributed across different backend servers!

## üìä Access Points

Once running, you have access to:

| URL | Purpose | Description |
|-----|---------|-------------|
| `http://localhost:8080` | **Load Balancer** | Your main application traffic |
| `http://localhost:8080/docs/` | **API Documentation** | Complete Swagger documentation |
| `http://localhost:8080/health` | **Health Check** | Simple health status |
| `http://localhost:8080/metrics` | **Metrics** | Prometheus metrics |
| `http://localhost:8080/api/v1/admin/` | **Admin API** | Runtime management |

## üîß Common Configurations

### Web Application Load Balancer
```bash
export LB_BACKENDS="http://web1:8080,http://web2:8080,http://web3:8080"
export LB_STRATEGY="round_robin"
export LB_PORT=8080
./bin/load-balancer
```

### API Gateway with IP Hash (Session Affinity)
```bash
export LB_BACKENDS="http://api1:3000,http://api2:3000"
export LB_STRATEGY="ip_hash"  # Same client always goes to same backend
export LB_PORT=80
./bin/load-balancer
```

### Database Read Replicas
```bash
export LB_BACKENDS="http://db-read1:5432,http://db-read2:5432,http://db-read3:5432"
export LB_STRATEGY="weighted"
export LB_PORT=5432
./bin/load-balancer
```

### Microservices with Custom Weights
```bash
export LB_BACKENDS="http://service1:8080:100,http://service2:8080:200,http://service3:8080:50"
export LB_STRATEGY="weighted"  # service2 gets 2x traffic, service3 gets 0.5x
./bin/load-balancer
```

## üõ†Ô∏è Runtime Management

### Add Backend Server (No Restart Required!)
```bash
curl -X POST http://localhost:8080/api/v1/admin/backends \
  -H "Content-Type: application/json" \
  -d '{
    "id": "new-server",
    "url": "http://new-server:8080",
    "weight": 100,
    "health_check_path": "/health"
  }'
```

### Remove Backend Server
```bash
curl -X DELETE http://localhost:8080/api/v1/admin/backends/backend-id
```

### Check Current Status
```bash
# Quick health check
curl http://localhost:8080/health

# Detailed status with metrics
curl http://localhost:8080/api/v1/health | jq

# List all backends
curl http://localhost:8080/api/v1/admin/backends | jq
```

### View Real-time Statistics
```bash
curl http://localhost:8080/api/v1/admin/stats | jq
```

## üö¢ Production Deployment

### Docker Compose (Multi-Service)
```yaml
# docker-compose.yml
version: '3.8'
services:
  load-balancer:
    build: .
    ports:
      - "80:8080"
    environment:
      - LB_BACKENDS=http://app1:8080,http://app2:8080,http://app3:8080
      - LB_STRATEGY=round_robin
      - LB_LOG_LEVEL=info
    depends_on:
      - app1
      - app2
      - app3
    restart: unless-stopped

  app1:
    image: your-app:latest
    environment:
      - PORT=8080
  
  app2:
    image: your-app:latest
    environment:
      - PORT=8080
      
  app3:
    image: your-app:latest
    environment:
      - PORT=8080
```

Start with: `docker-compose up -d`

### Kubernetes Deployment
```yaml
# k8s-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: load-balancer
spec:
  replicas: 2
  selector:
    matchLabels:
      app: load-balancer
  template:
    metadata:
      labels:
        app: load-balancer
    spec:
      containers:
      - name: load-balancer
        image: load-balancer:latest
        ports:
        - containerPort: 8080
        env:
        - name: LB_BACKENDS
          value: "http://my-app-service:8080"
        - name: LB_STRATEGY
          value: "ip_hash"
---
apiVersion: v1
kind: Service
metadata:
  name: load-balancer-service
spec:
  selector:
    app: load-balancer
  ports:
  - port: 80
    targetPort: 8080
  type: LoadBalancer
```

Deploy with: `kubectl apply -f k8s-deployment.yaml`

## üîç Monitoring & Observability

### Prometheus Integration
```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'load-balancer'
    static_configs:
      - targets: ['localhost:8080']
    metrics_path: '/metrics'
    scrape_interval: 15s
```

### Grafana Dashboard
Import dashboard with these key metrics:
- Request rate: `rate(http_requests_total[5m])`
- Error rate: `rate(http_requests_total{status=~"5.."}[5m])`
- Response time: `histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))`

### Log Analysis
```bash
# Structured JSON logs for easy parsing
tail -f /var/log/load-balancer.log | jq '{time, level, msg, backend_id, status_code}'
```

## ‚öôÔ∏è Configuration Options

### Environment Variables
```bash
# Core settings
export LB_PORT=8080                    # Load balancer port
export LB_BACKENDS="url1,url2,url3"   # Backend URLs
export LB_STRATEGY="round_robin"       # Load balancing strategy

# Advanced settings
export LB_MAX_RETRIES=3               # Failed request retries
export LB_TIMEOUT=30s                 # Request timeout
export LB_LOG_LEVEL=info              # Logging level

# Health checks
export LB_HEALTH_INTERVAL=30s         # Health check frequency
export LB_HEALTH_TIMEOUT=5s           # Health check timeout

# Security
export LB_RATE_LIMIT=100              # Requests per second limit
export LB_ENABLE_CORS=true            # Enable CORS headers
```

### Configuration File (Alternative)
```json
{
  "load_balancer": {
    "port": 8080,
    "strategy": "round_robin",
    "max_retries": 3,
    "timeout": "30s"
  },
  "backends": [
    {
      "id": "app1",
      "url": "http://app1:8080",
      "weight": 100,
      "health_check_path": "/health"
    }
  ],
  "metrics": {
    "enabled": true,
    "port": 8080
  }
}
```

## üß™ Testing & Validation

### Load Testing with Apache Bench
```bash
# Test load balancing performance
ab -n 10000 -c 100 http://localhost:8080/

# Test specific endpoint
ab -n 1000 -c 50 http://localhost:8080/api/users
```

### Automated Health Checks
```bash
#!/bin/bash
# health-check.sh

while true; do
  status=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:8080/health)
  if [ $status -eq 200 ]; then
    echo "‚úÖ Load balancer healthy"
  else
    echo "‚ùå Load balancer unhealthy (status: $status)"
    # Add alerting logic here
  fi
  sleep 30
done
```

### Backend Failover Testing
```bash
# Stop one backend and verify traffic continues
docker stop backend-1

# Check that load balancer detects the failure
curl http://localhost:8080/api/v1/health

# Restart backend and verify it's added back
docker start backend-1
```

## üîß Troubleshooting

### Common Issues

**Backend Connection Refused**:
```bash
# Check if backends are accessible
curl http://backend-url:port/health

# Verify backend configuration
curl http://localhost:8080/api/v1/admin/backends
```

**High Memory Usage**:
```bash
# Check resource usage
curl http://localhost:8080/api/v1/admin/stats

# Enable memory profiling
export LB_DEBUG=true
```

**Load Not Distributing Evenly**:
```bash
# Verify strategy setting
curl http://localhost:8080/api/v1/admin/config

# Check backend weights (for weighted strategy)
curl http://localhost:8080/api/v1/admin/backends
```

### Debug Mode
```bash
# Enable detailed logging
export LB_LOG_LEVEL=debug
./bin/load-balancer

# View request traces
tail -f /var/log/load-balancer.log | grep "request_trace"
```

## üìà Performance Benchmarks

**Typical Performance** (on modern hardware):
- **Throughput**: 50,000+ requests/second
- **Memory**: ~45MB baseline usage
- **CPU**: ~25% utilization at 10k req/sec
- **Latency**: <1ms overhead per request

**Scaling Limits**:
- **Backends**: 1000+ backends supported
- **Concurrent Connections**: 100,000+
- **Daily Requests**: Billions

## üÜò Getting Help

**Quick Reference**:
1. **Logs**: Check `/var/log/load-balancer.log` or Docker logs
2. **Health**: Visit `http://localhost:8080/health`
3. **Config**: Check `http://localhost:8080/api/v1/admin/config`
4. **Docs**: Full API docs at `http://localhost:8080/docs/`

**Support Channels**:
- üìñ [Technical Documentation](./TECHNICAL_DOCUMENTATION.md)
- üêõ [GitHub Issues](https://github.com/Mir00r/Load-Balancer/issues)
- üí¨ [Community Discussions](https://github.com/Mir00r/Load-Balancer/discussions)

## üéØ Next Steps

1. **Production Hardening**: Review [security configuration](./TECHNICAL_DOCUMENTATION.md#security)
2. **Monitoring Setup**: Configure [Prometheus/Grafana](./TECHNICAL_DOCUMENTATION.md#monitoring)
3. **Scaling Strategy**: Plan for [horizontal scaling](./TECHNICAL_DOCUMENTATION.md#scaling)
4. **Backup/Recovery**: Implement [configuration backup](./TECHNICAL_DOCUMENTATION.md#backup)

---

**Happy Load Balancing!** üöÄ

For detailed information, see the complete [Technical Documentation](./TECHNICAL_DOCUMENTATION.md).
